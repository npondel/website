<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on Nick Pondel</title>
    <link>/tags/r/</link>
    <description>Recent content in R on Nick Pondel</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Aug 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/r/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Thank you, TidyR</title>
      <link>/2020/08/21/thank-you-tidyr/</link>
      <pubDate>Fri, 21 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/08/21/thank-you-tidyr/</guid>
      <description>While I was working on my MPH program, I had to solve a problem which at the time seemed like a complex task. Combining and transforming some “messy” data with multiple rows per encounter into a tidy dataset for NLP analysis.
messy.data ## id text ## 1 1 hi ## 2 1 some data ## 3 2 woo hoo ## 4 2 more character strings ## 5 3 help me ## 6 4 tidyr as.</description>
    </item>
    
  </channel>
</rss>